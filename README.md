# Simple RAG System

A complete Retrieval-Augmented Generation (RAG) system built from scratch for PDF documents using FastAPI, Streamlit, and Mistral AI. This system implements hybrid search (TF-IDF + semantic), MMR diversification, and grounded answer generation with citations.

## ğŸŒŸ Features

- **ğŸ“„ PDF Processing**: Extract text from PDF documents using pdfminer.six
- **ğŸ” Hybrid Search**: Combines TF-IDF keyword search with semantic similarity
- **ğŸ¯ Smart Retrieval**: MMR (Maximal Marginal Relevance) for result diversification
- **ğŸ¤– Grounded Generation**: Uses Mistral AI with strict citation requirements
- **âš¡ FastAPI Backend**: RESTful API with `/ingest` and `/query` endpoints
- **ğŸ¨ Streamlit UI**: Interactive web interface with local or backend modes
- **ğŸ’¾ SQLite Storage**: Lightweight database with optimized vector storage
- **ğŸ›¡ï¸ Safety Features**: Evidence thresholds, hallucination filters, and disclaimers

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Streamlit UI   â”‚    â”‚   FastAPI API   â”‚
â”‚  (Local/Remote) â”‚â—„â”€â”€â–ºâ”‚   (/ingest,     â”‚
â”‚                 â”‚    â”‚    /query)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚  SQLite Database â”‚
            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
            â”‚  â”‚ Documents   â”‚ â”‚
            â”‚  â”‚ Chunks      â”‚ â”‚
            â”‚  â”‚ Embeddings  â”‚ â”‚
            â”‚  â”‚ TF-IDF      â”‚ â”‚
            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚   Mistral AI     â”‚
            â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
            â”‚  â”‚ Embeddings  â”‚ â”‚
            â”‚  â”‚ Generation  â”‚ â”‚
            â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ”§ Pipeline Overview

### 1. **Ingestion Pipeline**
```
PDF â†’ Text Extraction â†’ Chunking â†’ TF-IDF Indexing â†’ Embedding â†’ Storage
```

### 2. **Query Pipeline**
```
Query â†’ Intent Detection â†’ Rewriting â†’ Hybrid Search â†’ MMR â†’ Generation â†’ Citations
```

### 3. **Hybrid Retrieval**
- **TF-IDF**: `tf = 1 + log(count)`, `idf = log(N/(1+df))`
- **Semantic**: Cosine similarity on L2-normalized Mistral embeddings
- **Fusion**: `score = Î±Ã—semantic + (1-Î±)Ã—keyword` (default Î±=0.65)
- **MMR**: `Î»Ã—relevance - (1-Î»)Ã—max_similarity` for diversification

## ğŸš€ Quick Start

### 1. Setup Environment

```bash
# Clone and navigate to the project
cd simple-rag

# Create virtual environment
uv venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# Install dependencies
uv add fastapi uvicorn requests numpy pdfminer.six pydantic streamlit python-multipart
uv add --dev ruff pytest basedpyright
```

### 2. Configure API Keys

Copy `.env.example` to `.env` and add your Mistral API key:

```bash
cp .env.example .env
```

Edit `.env`:
```env
MISTRAL_API_KEY=your_mistral_api_key_here
MISTRAL_EMBED_MODEL=mistral-embed
MISTRAL_CHAT_MODEL=mistral-large-latest
DB_PATH=rag.sqlite3
```

### 3. Run the System

**Option A: Streamlit UI (Local Mode)**
```bash
uv run streamlit run ui/streamlit_app.py
```

**Option B: FastAPI Backend**
```bash
uv run uvicorn app.main:app --reload --port 8000
```

**Option C: Both (Backend + UI)**
```bash
# Terminal 1: Start backend
uv run uvicorn app.main:app --reload --port 8000

# Terminal 2: Set backend URL and start UI
export BACKEND_URL=http://localhost:8000
uv run streamlit run ui/streamlit_app.py
```

## ğŸ“š Usage

### API Endpoints

**Ingest Documents** (`POST /ingest`)
```bash
curl -X POST "http://localhost:8000/ingest" \
  -F "files=@document1.pdf" \
  -F "files=@document2.pdf"
```

Response:
```json
{
  "documents": [
    {"id": 1, "filename": "document1.pdf", "pages": 10}
  ],
  "chunks_indexed": 45,
  "success": true
}
```

**Query Documents** (`POST /query`)
```bash
curl -X POST "http://localhost:8000/query" \
  -H "Content-Type: application/json" \
  -d '{
    "query": "What are the key benefits of machine learning?",
    "top_k": 5,
    "threshold": 0.18
  }'
```

Response:
```json
{
  "answer": "Machine learning offers several key benefits [document1.pdf p.3]: automated decision making, pattern recognition, and predictive analytics...",
  "citations": [
    {
      "chunk_id": 42,
      "filename": "document1.pdf",
      "page": 3,
      "snippet": "Machine learning algorithms can automate..."
    }
  ],
  "insufficient_evidence": false,
  "intent": "qa"
}
```

### Streamlit Interface

1. **Upload PDFs**: Use the sidebar file uploader
2. **Configure Parameters**: Adjust retrieval settings
3. **Ask Questions**: Type in the chat interface
4. **View Citations**: Expand citation panels for sources

## âš™ï¸ Configuration

### Retrieval Parameters

| Parameter | Default | Description |
|-----------|---------|-------------|
| `top_k` | 8 | Final results to return |
| `rerank_k` | 20 | Candidates for reranking |
| `threshold` | 0.18 | Min semantic similarity |
| `alpha` | 0.65 | Semantic vs keyword weight |
| `lambda_param` | 0.7 | MMR relevance vs diversity |

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `MISTRAL_API_KEY` | - | Your Mistral AI API key |
| `MISTRAL_EMBED_MODEL` | mistral-embed | Embedding model |
| `MISTRAL_CHAT_MODEL` | mistral-large-latest | Chat model |
| `DB_PATH` | rag.sqlite3 | Database file path |
| `CHUNK_SIZE` | 1800 | Target chunk size (chars) |
| `CHUNK_OVERLAP` | 200 | Overlap between chunks |

## ğŸ§ª Testing

Run the test suite:

```bash
# Run all tests
uv run pytest

# Run specific test files
uv run pytest tests/test_chunker.py
uv run pytest tests/test_tfidf.py -v

# Run with coverage
uv run pytest --cov=app tests/
```

Test coverage includes:
- âœ… Chunking algorithms and overlap
- âœ… TF-IDF calculation and indexing
- âœ… Semantic search and cosine similarity
- âœ… Hybrid fusion and MMR diversification
- âœ… Database operations
- âœ… API endpoint functionality

## ğŸ“ Project Structure

```
simple-rag/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                    # FastAPI application
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ ingest.py             # Document ingestion endpoint
â”‚   â”‚   â””â”€â”€ query.py              # Query processing endpoint
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ config.py             # Configuration settings
â”‚   â”‚   â””â”€â”€ models.py             # Pydantic schemas
â”‚   â”œâ”€â”€ ingest/
â”‚   â”‚   â”œâ”€â”€ pdf_extractor.py      # PDF text extraction
â”‚   â”‚   â””â”€â”€ chunker.py            # Text chunking with overlap
â”‚   â”œâ”€â”€ retriever/
â”‚   â”‚   â”œâ”€â”€ index.py              # SQLite database operations
â”‚   â”‚   â”œâ”€â”€ keyword.py            # TF-IDF search implementation
â”‚   â”‚   â”œâ”€â”€ semantic.py           # Cosine similarity search
â”‚   â”‚   â””â”€â”€ fusion.py             # Hybrid fusion and MMR
â”‚   â”œâ”€â”€ llm/
â”‚   â”‚   â”œâ”€â”€ mistral_client.py     # Mistral API client
â”‚   â”‚   â””â”€â”€ prompts.py            # Prompt templates
â”‚   â””â”€â”€ logic/
â”‚       â”œâ”€â”€ intent.py             # Query intent detection
â”‚       â””â”€â”€ postprocess.py        # Citation processing
â”œâ”€â”€ ui/
â”‚   â””â”€â”€ streamlit_app.py          # Streamlit interface
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_chunker.py           # Chunking tests
â”‚   â”œâ”€â”€ test_tfidf.py             # TF-IDF tests
â”‚   â”œâ”€â”€ test_semantic.py          # Semantic search tests
â”‚   â””â”€â”€ test_fusion.py            # Fusion and MMR tests
â”œâ”€â”€ .env.example                  # Environment template
â”œâ”€â”€ pyproject.toml               # UV project config
â””â”€â”€ README.md                    # This file
```

## ğŸ›¡ï¸ Safety & Guardrails

### Evidence Thresholds
- **Semantic Threshold**: Minimum cosine similarity (default: 0.18)
- **Insufficient Evidence**: Returns refusal when support is weak
- **Citation Requirements**: All claims must include `[filename p.X]` citations

### Intent Detection
- **Smalltalk**: Friendly responses for greetings/thanks
- **Structured**: Bullet points/lists for enumeration requests
- **Comparison**: Side-by-side analysis format
- **Q&A**: Standard question-answering

### Content Safety
- **PII Detection**: Warns about personal information
- **Medical/Legal**: Adds disclaimers for sensitive topics
- **Hallucination Filter**: Optional sentence-level verification

## ğŸ¯ Design Decisions

### Why No External Vector DBs?
- **Simplicity**: SQLite BLOB storage is sufficient for most use cases
- **Portability**: Single-file database, easy deployment
- **Performance**: L2-normalized vectors + numpy for cosine similarity
- **Cost**: No additional infrastructure or API costs

### Why Hybrid Search?
- **Keyword Strengths**: Exact term matching, acronyms, proper nouns
- **Semantic Strengths**: Conceptual similarity, paraphrases, context
- **Best of Both**: Î±-weighted combination captures diverse relevance signals

### Why MMR Diversification?
- **Avoid Redundancy**: Prevents similar chunks from dominating results
- **Better Coverage**: Ensures diverse aspects of topics are represented
- **User Experience**: More informative and comprehensive answers

## ğŸš€ Production Deployment

### Docker Deployment

Create `Dockerfile`:
```dockerfile
FROM python:3.13-slim

WORKDIR /app
COPY . .

RUN pip install uv
RUN uv venv && uv add fastapi uvicorn streamlit [other deps]

EXPOSE 8000
CMD ["uv", "run", "uvicorn", "app.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### Streamlit Deployment

For Streamlit Cloud deployment:

1. Create `.streamlit/secrets.toml`:
```toml
MISTRAL_API_KEY = "your_key_here"
DB_PATH = "rag.sqlite3"
```

2. Add to requirements:
```txt
fastapi
streamlit
pdfminer.six
numpy
requests
pydantic
```

### Environment Setup

**Production considerations**:
- Use environment-specific API keys
- Configure proper logging levels
- Set up health checks and monitoring
- Consider rate limiting for API endpoints
- Use proper CORS settings for web deployment

## ğŸ“Š Performance Tuning

### Database Optimizations
- **Indexes**: Created on frequently queried columns
- **WAL Mode**: Better concurrency for SQLite
- **Batch Operations**: Bulk embedding insertions
- **Connection Pooling**: Reuse database connections

### Search Optimizations
- **Embedding Cache**: In-memory storage of embeddings
- **Precomputed Norms**: L2-normalized storage
- **Token Filtering**: Stopword removal, minimum length
- **Result Limiting**: Configurable top-k and rerank-k

### Memory Usage
- **Streaming**: Process large PDFs in chunks
- **Lazy Loading**: Load embeddings on first search
- **Cache Management**: Clear caches when memory is tight
- **Batch Size**: Configurable batch sizes for embedding API calls

## ğŸ¤ Contributing

1. **Code Style**: Use `ruff` for linting and formatting
2. **Testing**: Add tests for new features
3. **Documentation**: Update docstrings and README
4. **Type Hints**: Use proper Python type annotations

```bash
# Format code
uv run ruff format .

# Lint code
uv run ruff check .

# Type checking
uv run basedpyright
```

## ğŸ“„ License

This project is provided as-is for educational and research purposes. Please review the licenses of all dependencies:

- **FastAPI**: MIT License
- **Streamlit**: Apache 2.0 License
- **pdfminer.six**: MIT License
- **NumPy**: BSD License
- **Mistral AI**: API Terms of Service

## ğŸ™ Acknowledgments

Built following the detailed requirements in `instructions.md`. This implementation demonstrates:

- **No External Dependencies**: Custom TF-IDF, cosine similarity, and MMR implementations
- **Production Ready**: Comprehensive error handling, logging, and testing
- **Scalable Design**: Modular architecture with clear separation of concerns
- **Educational Value**: Well-documented code showing RAG system internals

**References:**
- [Mistral AI API Documentation](https://docs.mistral.ai/)
- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [Streamlit Documentation](https://docs.streamlit.io/)
- [PDFMiner Documentation](https://pdfminersix.readthedocs.io/)

---

**Note**: Remember to set your `MISTRAL_API_KEY` environment variable before running the system!

For questions or issues, please refer to the inline documentation in the code or create an issue in the repository.
